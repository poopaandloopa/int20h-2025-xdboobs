{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 94006,
     "databundleVersionId": 11246485,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:55:00.304413Z",
     "start_time": "2025-03-01T22:55:00.296361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:55:06.518096Z",
     "start_time": "2025-03-01T22:55:06.514082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_merchant_folders(input_folder):\n",
    "    return [os.path.join(input_folder, d) for d in os.listdir(input_folder)\n",
    "            if os.path.isdir(os.path.join(input_folder, d)) and d.startswith(\"merchant\")]"
   ],
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:55:07.252383Z",
     "start_time": "2025-03-01T22:55:07.247763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_orders_by_merchant(folder_path):\n",
    "    orders_folder = os.path.join(folder_path, \"orders\")\n",
    "\n",
    "    usecols = [\"transaction_id\", \"created_at\", \"merchant_id\"]\n",
    "    dtypes = {\"transaction_id\": \"object\", \"merchant_id\": \"object\"}\n",
    "    orders_df = pd.concat([pd.read_csv(os.path.join(orders_folder, f),\n",
    "                                       usecols=usecols,\n",
    "                                       parse_dates=[\"created_at\"],\n",
    "                                       dtype=dtypes) for f in tqdm(os.listdir(orders_folder)) if f.endswith(\".csv\")],\n",
    "                           ignore_index=True) if os.path.exists(orders_folder) else pd.DataFrame()\n",
    "    return orders_df"
   ],
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:55:08.628496Z",
     "start_time": "2025-03-01T22:55:08.624492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_orders_df(input_folder):\n",
    "    merchant_folders = find_merchant_folders(input_folder)\n",
    "    dataframes = [get_orders_by_merchant(folder) for folder in merchant_folders]\n",
    "\n",
    "    # Stack all merchant DataFrames together\n",
    "    final_df = pd.concat(dataframes, ignore_index=True) if dataframes else pd.DataFrame()\n",
    "    return final_df"
   ],
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:55:09.614799Z",
     "start_time": "2025-03-01T22:55:09.607519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_chargebacks_df(input_folder):\n",
    "    merchant_folders = find_merchant_folders(input_folder)\n",
    "\n",
    "    usecols = [\"transaction_id\", \"created_at\"]\n",
    "    dtypes = {\"transaction_id\": \"object\"}\n",
    "\n",
    "    dfs = []\n",
    "    for folder in merchant_folders:\n",
    "        merchant_id = os.path.basename(folder).split(\"_\")[1]\n",
    "        merchant_chargebacks = pd.read_csv(os.path.join(folder, \"chargebacks.csv\"),\n",
    "                               usecols=usecols,\n",
    "                               parse_dates=[\"created_at\"],\n",
    "                               dtype=dtypes)\n",
    "        merchant_chargebacks[\"merchant_id\"] = merchant_id\n",
    "        dfs.append(merchant_chargebacks)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def get_fraud_alerts_df(input_folder):\n",
    "    merchant_folders = find_merchant_folders(input_folder)\n",
    "\n",
    "    usecols = [\"transaction_id\", \"created_at\"]\n",
    "    dtypes = {\"transaction_id\": \"object\"}\n",
    "\n",
    "    dfs = []\n",
    "    for folder in merchant_folders:\n",
    "        merchant_id = os.path.basename(folder).split(\"_\")[1]\n",
    "        merchant_fraud_alerts = pd.read_csv(os.path.join(folder, \"fraud_alerts.csv\"),\n",
    "                               usecols=usecols,\n",
    "                               parse_dates=[\"created_at\"],\n",
    "                               dtype=dtypes)\n",
    "        merchant_fraud_alerts[\"merchant_id\"] = merchant_id\n",
    "        dfs.append(merchant_fraud_alerts)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "source": [
    "def aggregate_and_merge(orders_df: pd.DataFrame,\n",
    "                        chargebacks_df: pd.DataFrame,\n",
    "                        fraud_alerts_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    orders_df[\"created_at\"] = pd.to_datetime(orders_df[\"created_at\"]).dt.floor(\"D\")\n",
    "    chargebacks_df[\"created_at\"] = pd.to_datetime(chargebacks_df[\"created_at\"]).dt.floor(\"D\")\n",
    "    fraud_alerts_df[\"created_at\"] = pd.to_datetime(fraud_alerts_df[\"created_at\"]).dt.floor(\"D\")\n",
    "\n",
    "    orders_agg = orders_df.groupby([\"merchant_id\", \"created_at\"]).agg(orders_count=(\"transaction_id\", \"count\")).reset_index()\n",
    "    orders_agg.rename(columns={\"created_at\": \"date\"}, inplace=True)\n",
    "\n",
    "    chargebacks_agg = chargebacks_df.groupby([\"merchant_id\", \"created_at\"]).agg(chargebacks_count=(\"transaction_id\", \"count\")).reset_index()\n",
    "    chargebacks_agg.rename(columns={\"created_at\": \"date\"}, inplace=True)\n",
    "\n",
    "    fraud_alerts_agg = fraud_alerts_df.groupby([\"merchant_id\", \"created_at\"]).agg(fraud_alerts_count=(\"transaction_id\", \"count\")).reset_index()\n",
    "    fraud_alerts_agg.rename(columns={\"created_at\": \"date\"}, inplace=True)\n",
    "\n",
    "    df = pd.merge(orders_agg, chargebacks_agg, on=[\"merchant_id\", \"date\"], how=\"outer\")\n",
    "    df = pd.merge(df, fraud_alerts_agg, on=[\"merchant_id\", \"date\"], how=\"outer\")\n",
    "    df[[\"orders_count\", \"chargebacks_count\", \"fraud_alerts_count\"]] = df[[\"orders_count\", \"chargebacks_count\", \"fraud_alerts_count\"]].fillna(0)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-03-01T22:55:10.752402Z",
     "start_time": "2025-03-01T22:55:10.745868Z"
    }
   },
   "outputs": [],
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_rolling_risk(group, window=30):\n",
    "    group = group.sort_values(\"date\")\n",
    "    group[\"orders_roll_sum_30\"] = group[\"orders_count\"].rolling(window=window, min_periods=1).sum().shift(1)\n",
    "    group[\"risk_events_roll_sum_30\"] = (group[\"chargebacks_count\"] + group[\"fraud_alerts_count\"]).rolling(window=window, min_periods=1).sum().shift(1)\n",
    "    group[\"rolling_risk_metric_30\"] = 100 * (group[\"risk_events_roll_sum_30\"] / (group[\"orders_roll_sum_30\"] + 1e-6))\n",
    "    return group\n",
    "\n",
    "\n",
    "def create_extended_lag_features(group, lags=[1, 3, 5, 7, 14, 30, 60, 90]):\n",
    "    group = group.sort_values(\"date\")\n",
    "    # Create lags for orders, chargebacks, fraud alerts and their sum (risk events)\n",
    "    for lag in lags:\n",
    "        group[f'orders_lag_{lag}'] = group['orders_count'].shift(lag)\n",
    "        group[f'chargebacks_lag_{lag}'] = group['chargebacks_count'].shift(lag)\n",
    "        group[f'fraud_alerts_lag_{lag}'] = group['fraud_alerts_count'].shift(lag)\n",
    "        group[f'risk_events_lag_{lag}'] = (group[\"chargebacks_count\"] + group[\"fraud_alerts_count\"]).shift(lag)\n",
    "    return group\n",
    "\n",
    "\n",
    "def create_multiple_window_features(group, windows=[7, 14, 30, 60, 90]):\n",
    "    group = group.sort_values(\"date\")\n",
    "    for w in windows:\n",
    "        group[f'orders_roll_sum_{w}'] = group['orders_count'].rolling(window=w, min_periods=1).sum().shift(1)\n",
    "        group[f'risk_events_roll_sum_{w}'] = (group['chargebacks_count'] + group['fraud_alerts_count']).rolling(window=w, min_periods=1).sum().shift(1)\n",
    "    return group\n",
    "\n",
    "\n",
    "def create_exponential_decay_features(group, span=7):\n",
    "    group = group.sort_values(\"date\")\n",
    "    group[\"orders_ewm_mean\"] = group[\"orders_count\"].ewm(span=span, adjust=False).mean().shift(1)\n",
    "    group[\"chargebacks_ewm_mean\"] = group[\"chargebacks_count\"].ewm(span=span, adjust=False).mean().shift(1)\n",
    "    group[\"fraud_alerts_ewm_mean\"] = group[\"fraud_alerts_count\"].ewm(span=span, adjust=False).mean().shift(1)\n",
    "    group[\"risk_events_ewm_mean\"] = (group[\"chargebacks_count\"] + group[\"fraud_alerts_count\"]).ewm(span=span, adjust=False).mean().shift(1)\n",
    "    group[\"rolling_risk_metric_ewm\"] = 100 * (group[\"risk_events_ewm_mean\"] / (group[\"orders_ewm_mean\"] + 1e-6))\n",
    "    return group\n",
    "\n",
    "\n",
    "def create_ratio_features(group, windows=[7, 14, 30, 60, 90]):\n",
    "    group = group.sort_values(\"date\")\n",
    "    for w in windows:\n",
    "        group[f'risk_to_orders_ratio_{w}'] = group[f'risk_events_roll_sum_{w}'] / (group[f'orders_roll_sum_{w}'] + 1e-6)\n",
    "    if \"risk_to_orders_ratio_14\" in group.columns and \"risk_to_orders_ratio_7\" in group.columns:\n",
    "        group['risk_ratio_diff_14_7'] = group['risk_to_orders_ratio_14'] - group['risk_to_orders_ratio_7']\n",
    "    if \"risk_to_orders_ratio_30\" in group.columns and \"risk_to_orders_ratio_14\" in group.columns:\n",
    "        group['risk_ratio_diff_30_14'] = group['risk_to_orders_ratio_30'] - group['risk_to_orders_ratio_14']\n",
    "    return group\n",
    "\n",
    "\n",
    "def create_time_based_and_seasonal_features(df: pd.DataFrame):\n",
    "    df[\"day_of_week\"] = df[\"date\"].dt.dayofweek\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"date_ordinal\"] = df[\"date\"].map(pd.Timestamp.toordinal)\n",
    "    df[\"day_of_year\"] = df[\"date\"].dt.dayofyear\n",
    "    df[\"sin_day\"] = np.sin(2 * np.pi * df[\"day_of_year\"] / 365)\n",
    "    df[\"cos_day\"] = np.cos(2 * np.pi * df[\"day_of_year\"] / 365)\n",
    "    df[\"sin_month\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
    "    df[\"cos_month\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
    "\n",
    "    return df\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:55:11.977907Z",
     "start_time": "2025-03-01T22:55:11.963607Z"
    }
   },
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:55:13.206838Z",
     "start_time": "2025-03-01T22:55:13.200784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    transforms = [compute_rolling_risk,\n",
    "                  create_extended_lag_features,\n",
    "                  create_multiple_window_features,\n",
    "                  create_exponential_decay_features,\n",
    "                  create_ratio_features]\n",
    "    for transform in transforms:\n",
    "        df = df.groupby(\"merchant_id\", group_keys=False).apply(transform)\n",
    "\n",
    "    df = create_time_based_and_seasonal_features(df)\n",
    "\n",
    "    for lag in [1, 2, 3]:\n",
    "        df[f'rolling_risk_metric_lag_{lag}'] = df.groupby(\"merchant_id\")[\"rolling_risk_metric_30\"].shift(lag)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:55:16.137874Z",
     "start_time": "2025-03-01T22:55:16.132140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import boto3\n",
    "import io\n",
    "\n",
    "def save_dataframe_to_s3(df: pd.DataFrame, bucket_name: str, file_key: str):\n",
    "    buffer = io.BytesIO()\n",
    "    df.to_parquet(buffer, engine='pyarrow', index=False)\n",
    "    buffer.seek(0)\n",
    "\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "        aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "    )\n",
    "\n",
    "    s3_client.upload_fileobj(buffer, bucket_name, file_key)\n",
    "    print(f\"File saved to s3://{bucket_name}/{file_key}\")"
   ],
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:55:17.193373Z",
     "start_time": "2025-03-01T22:55:17.188811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def data_processing_pipeline(data_folder: str) -> pd.DataFrame:\n",
    "    print(\"Prepare orders df\")\n",
    "    orders_df = get_orders_df(data_folder)\n",
    "    print(\"Prepare chargebacks df\")\n",
    "    chargebacks_df = get_chargebacks_df(data_folder)\n",
    "    print(\"Prepare fraud alerts df\")\n",
    "    fraud_alerts_df = get_fraud_alerts_df(data_folder)\n",
    "\n",
    "    print(\"Aggregate and merge\")\n",
    "    df = aggregate_and_merge(orders_df, chargebacks_df, fraud_alerts_df)\n",
    "    print(\"Create new features\")\n",
    "    df = create_features(df)\n",
    "    print(\"Saving to S3\")\n",
    "    save_dataframe_to_s3(df, os.getenv(\"BUCKET_NAME\"), \"data/processed_data.parquet\")\n",
    "\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:58:16.283394Z",
     "start_time": "2025-03-01T22:55:30.224472Z"
    }
   },
   "cell_type": "code",
   "source": "processed_df = data_processing_pipeline(\"../data\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare orders df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:30<00:00,  1.38s/it]\n",
      "100%|██████████| 16/16 [00:06<00:00,  2.55it/s]\n",
      "100%|██████████| 22/22 [01:59<00:00,  5.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare chargebacks df\n",
      "Prepare fraud alerts df\n",
      "Aggregate and merge\n",
      "Create new features\n",
      "Saving to S3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrk\\AppData\\Local\\Temp\\ipykernel_12544\\1641976080.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"merchant_id\", group_keys=False).apply(transform)\n",
      "C:\\Users\\andrk\\AppData\\Local\\Temp\\ipykernel_12544\\1641976080.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"merchant_id\", group_keys=False).apply(transform)\n",
      "C:\\Users\\andrk\\AppData\\Local\\Temp\\ipykernel_12544\\1641976080.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"merchant_id\", group_keys=False).apply(transform)\n",
      "C:\\Users\\andrk\\AppData\\Local\\Temp\\ipykernel_12544\\1641976080.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"merchant_id\", group_keys=False).apply(transform)\n",
      "C:\\Users\\andrk\\AppData\\Local\\Temp\\ipykernel_12544\\1641976080.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"merchant_id\", group_keys=False).apply(transform)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to s3://int20h-data/data/processed_data.parquet\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T23:04:59.317345Z",
     "start_time": "2025-03-01T23:04:59.307337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "def read_dataframe_from_s3(bucket_name: str, file_key: str) -> pd.DataFrame:\n",
    "    s3_client = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "            aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "        )\n",
    "\n",
    "    # Download file into a buffer\n",
    "    buffer = io.BytesIO()\n",
    "    s3_client.download_fileobj(bucket_name, file_key, buffer)\n",
    "    buffer.seek(0)  # Reset buffer position\n",
    "\n",
    "    # Read Parquet file into DataFrame\n",
    "    df = pd.read_parquet(buffer, engine='pyarrow')\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_training_data(df: pd.DataFrame, feature_cols: list[str], target_col: str):\n",
    "    return df[feature_cols], df[target_col]\n",
    "\n",
    "\n",
    "def select_hyperparameters(data, target):\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.5)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 100, 800, step=100)\n",
    "        subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n",
    "        reg_alpha = trial.suggest_float(\"reg_alpha\", 0.0, 10.0)\n",
    "        reg_lambda = trial.suggest_float(\"reg_lambda\", 1.0, 100.0)\n",
    "\n",
    "        model = XGBRegressor(\n",
    "            random_state=42,\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            n_estimators=n_estimators,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            reg_alpha=reg_alpha,\n",
    "            reg_lambda=reg_lambda,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        fold_scores = []\n",
    "        for train_idx, val_idx in tscv.split(data):\n",
    "            X_train, X_val = data.iloc[train_idx], data.iloc[val_idx]\n",
    "            y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_val)\n",
    "            score = r2_score(y_val, preds)\n",
    "            fold_scores.append(score)\n",
    "        return np.mean(fold_scores)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=30)\n",
    "\n",
    "    best_params = study.best_trial.params\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "    print(\"Best CV R²:\", study.best_trial.value)\n",
    "    return best_params\n",
    "\n",
    "def train_model(data: pd.DataFrame, target: pd.Series, best_params: dict):\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI_DEV\"))\n",
    "    mlflow.set_experiment(\"int20h-xdboobs\")\n",
    "    with mlflow.start_run(run_name=os.getenv(\"MLFLOW_RUN_NAME\")):\n",
    "        final_model = XGBRegressor(random_state=42, **best_params)\n",
    "        final_model.fit(data, target)\n",
    "\n",
    "        train_r2 = r2_score(target, final_model.predict(data))\n",
    "        mlflow.log_metric(\"R2\", train_r2)\n",
    "        for key, value in best_params.items():\n",
    "            mlflow.log_param(key, value)\n",
    "        mlflow.xgboost.log_model(final_model, \"xgboost_model\")\n"
   ],
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T23:52:45.424190Z",
     "start_time": "2025-03-01T23:52:45.416774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_feature_columns():\n",
    "    feature_columns = [\n",
    "    \"rolling_risk_metric_lag_1\", \"rolling_risk_metric_lag_2\", \"rolling_risk_metric_lag_3\",\n",
    "    # Extended lag features\n",
    "    \"orders_lag_1\", \"orders_lag_3\", \"orders_lag_5\", \"orders_lag_7\", \"orders_lag_14\", \"orders_lag_30\",\n",
    "    \"chargebacks_lag_1\", \"chargebacks_lag_3\", \"chargebacks_lag_5\", \"chargebacks_lag_7\", \"chargebacks_lag_14\", \"chargebacks_lag_30\",\n",
    "    \"fraud_alerts_lag_1\", \"fraud_alerts_lag_3\", \"fraud_alerts_lag_5\", \"fraud_alerts_lag_7\", \"fraud_alerts_lag_14\", \"fraud_alerts_lag_30\",\n",
    "    \"risk_events_lag_1\", \"risk_events_lag_3\", \"risk_events_lag_5\", \"risk_events_lag_7\", \"risk_events_lag_14\", \"risk_events_lag_30\",\n",
    "    # Rolling sums over multiple windows\n",
    "    \"orders_roll_sum_7\", \"orders_roll_sum_14\", \"orders_roll_sum_30\", \"orders_roll_sum_60\", \"orders_roll_sum_90\",\n",
    "    \"risk_events_roll_sum_7\", \"risk_events_roll_sum_14\", \"risk_events_roll_sum_30\", \"risk_events_roll_sum_60\", \"risk_events_roll_sum_90\",\n",
    "    # Ratio features\n",
    "    \"risk_to_orders_ratio_7\", \"risk_to_orders_ratio_14\", \"risk_to_orders_ratio_30\", \"risk_to_orders_ratio_60\", \"risk_to_orders_ratio_90\",\n",
    "    \"risk_ratio_diff_14_7\", \"risk_ratio_diff_30_14\",\n",
    "    # Exponential decay features\n",
    "    \"orders_ewm_mean\", \"chargebacks_ewm_mean\", \"fraud_alerts_ewm_mean\", \"risk_events_ewm_mean\", \"rolling_risk_metric_ewm\",\n",
    "    # Time and seasonal features\n",
    "    \"day_of_week\", \"month\", \"date_ordinal\",\n",
    "    \"sin_day\", \"cos_day\", \"sin_month\", \"cos_month\"\n",
    "    ]\n",
    "    return feature_columns"
   ],
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T23:06:12.000598Z",
     "start_time": "2025-03-01T23:04:59.704875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def model_training_pipeline():\n",
    "    processed_df = read_dataframe_from_s3(os.getenv(\"BUCKET_NAME\"), \"data/processed_data.parquet\")\n",
    "\n",
    "    feature_columns = get_feature_columns()\n",
    "    target_column = \"rolling_risk_metric_30\"\n",
    "\n",
    "    data, target = get_training_data(processed_df, feature_columns, target_column)\n",
    "    best_params = select_hyperparameters(data, target)\n",
    "    train_model(data, target, best_params)\n",
    "\n",
    "model_training_pipeline()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 01:05:00,656] A new study created in memory with name: no-name-b7f3a42b-fbc5-460c-b545-54abd804dea3\n",
      "[I 2025-03-02 01:05:01,196] Trial 0 finished with value: -0.0950136136628154 and parameters: {'learning_rate': 0.4472595491978774, 'max_depth': 15, 'n_estimators': 200, 'subsample': 0.6768120592977138, 'colsample_bytree': 0.9985071793993816, 'reg_alpha': 8.758320332067736, 'reg_lambda': 86.13472366830968}. Best is trial 0 with value: -0.0950136136628154.\n",
      "[I 2025-03-02 01:05:02,044] Trial 1 finished with value: 0.05574951804016196 and parameters: {'learning_rate': 0.31539615441631386, 'max_depth': 11, 'n_estimators': 400, 'subsample': 0.8181115150693915, 'colsample_bytree': 0.7147940350936048, 'reg_alpha': 2.1668681456004446, 'reg_lambda': 72.33422607151724}. Best is trial 1 with value: 0.05574951804016196.\n",
      "[I 2025-03-02 01:05:03,006] Trial 2 finished with value: -0.023358357933212726 and parameters: {'learning_rate': 0.420326968354153, 'max_depth': 10, 'n_estimators': 600, 'subsample': 0.9747533130818858, 'colsample_bytree': 0.9760154700900687, 'reg_alpha': 6.1595489133041035, 'reg_lambda': 83.90873611805395}. Best is trial 1 with value: 0.05574951804016196.\n",
      "[I 2025-03-02 01:05:03,450] Trial 3 finished with value: -0.038550234019131525 and parameters: {'learning_rate': 0.4200662005749048, 'max_depth': 8, 'n_estimators': 200, 'subsample': 0.9462657257154651, 'colsample_bytree': 0.8827943091716857, 'reg_alpha': 7.055893439127026, 'reg_lambda': 84.32927929189196}. Best is trial 1 with value: 0.05574951804016196.\n",
      "[I 2025-03-02 01:05:04,135] Trial 4 finished with value: 0.043528335370531135 and parameters: {'learning_rate': 0.1970493316158329, 'max_depth': 14, 'n_estimators': 200, 'subsample': 0.992659334995257, 'colsample_bytree': 0.6069388541622815, 'reg_alpha': 3.598216551579463, 'reg_lambda': 76.64922054792453}. Best is trial 1 with value: 0.05574951804016196.\n",
      "[I 2025-03-02 01:05:05,502] Trial 5 finished with value: 0.05345686308181996 and parameters: {'learning_rate': 0.3914526847351149, 'max_depth': 11, 'n_estimators': 700, 'subsample': 0.69034622334448, 'colsample_bytree': 0.8232680261925417, 'reg_alpha': 2.376303730238921, 'reg_lambda': 95.98312173374453}. Best is trial 1 with value: 0.05574951804016196.\n",
      "[I 2025-03-02 01:05:06,191] Trial 6 finished with value: 0.010896101675462807 and parameters: {'learning_rate': 0.29055962802725527, 'max_depth': 14, 'n_estimators': 300, 'subsample': 0.7853628627516498, 'colsample_bytree': 0.6206819565968894, 'reg_alpha': 3.7970298371791267, 'reg_lambda': 14.710681767308285}. Best is trial 1 with value: 0.05574951804016196.\n",
      "[I 2025-03-02 01:05:06,888] Trial 7 finished with value: -0.03041377235992826 and parameters: {'learning_rate': 0.018911776249600786, 'max_depth': 13, 'n_estimators': 200, 'subsample': 0.9208087155630036, 'colsample_bytree': 0.9332022780683784, 'reg_alpha': 3.9130653206342725, 'reg_lambda': 95.47849081097864}. Best is trial 1 with value: 0.05574951804016196.\n",
      "[I 2025-03-02 01:05:09,834] Trial 8 finished with value: 0.11621542443172732 and parameters: {'learning_rate': 0.021665472314467818, 'max_depth': 9, 'n_estimators': 600, 'subsample': 0.6001660456012744, 'colsample_bytree': 0.712617743774031, 'reg_alpha': 0.21310602266234713, 'reg_lambda': 77.94907815248472}. Best is trial 8 with value: 0.11621542443172732.\n",
      "[I 2025-03-02 01:05:10,631] Trial 9 finished with value: 0.030042142910974363 and parameters: {'learning_rate': 0.2882498488536216, 'max_depth': 7, 'n_estimators': 500, 'subsample': 0.6472496591022219, 'colsample_bytree': 0.9013708055396064, 'reg_alpha': 4.946913412677739, 'reg_lambda': 19.572791856668182}. Best is trial 8 with value: 0.11621542443172732.\n",
      "[I 2025-03-02 01:05:12,315] Trial 10 finished with value: 0.12742978422496246 and parameters: {'learning_rate': 0.010888603554030818, 'max_depth': 3, 'n_estimators': 800, 'subsample': 0.6054137876986674, 'colsample_bytree': 0.7232649267846188, 'reg_alpha': 0.2476906842606299, 'reg_lambda': 49.555833199599796}. Best is trial 10 with value: 0.12742978422496246.\n",
      "[I 2025-03-02 01:05:14,126] Trial 11 finished with value: 0.12261064568352013 and parameters: {'learning_rate': 0.010489424632957895, 'max_depth': 3, 'n_estimators': 800, 'subsample': 0.6164848581203008, 'colsample_bytree': 0.7260067682866737, 'reg_alpha': 0.3583249540335541, 'reg_lambda': 50.401043191044764}. Best is trial 10 with value: 0.12742978422496246.\n",
      "[I 2025-03-02 01:05:16,095] Trial 12 finished with value: 0.18825719440992336 and parameters: {'learning_rate': 0.10909373319085952, 'max_depth': 3, 'n_estimators': 800, 'subsample': 0.7494334255183932, 'colsample_bytree': 0.7309266965702423, 'reg_alpha': 0.004675858754265516, 'reg_lambda': 46.766727365670086}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:17,291] Trial 13 finished with value: 0.12049540786689865 and parameters: {'learning_rate': 0.13311473480274993, 'max_depth': 3, 'n_estimators': 800, 'subsample': 0.7488022623127322, 'colsample_bytree': 0.7810799539917661, 'reg_alpha': 1.459587795410744, 'reg_lambda': 44.52225469462612}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:19,136] Trial 14 finished with value: 0.13498061276065423 and parameters: {'learning_rate': 0.11062280006083777, 'max_depth': 5, 'n_estimators': 700, 'subsample': 0.8487155185993207, 'colsample_bytree': 0.6575838436777225, 'reg_alpha': 0.20805933778520602, 'reg_lambda': 28.854740025962172}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:20,369] Trial 15 finished with value: 0.08712791716312755 and parameters: {'learning_rate': 0.12473711282114859, 'max_depth': 6, 'n_estimators': 700, 'subsample': 0.8638538484634752, 'colsample_bytree': 0.6628919267137996, 'reg_alpha': 1.4982384543239036, 'reg_lambda': 31.6794119647492}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:21,353] Trial 16 finished with value: -0.021715002183475107 and parameters: {'learning_rate': 0.10551159996289962, 'max_depth': 5, 'n_estimators': 600, 'subsample': 0.8662358694220671, 'colsample_bytree': 0.7997105880109251, 'reg_alpha': 8.729455025959961, 'reg_lambda': 1.978718722347594}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:22,422] Trial 17 finished with value: 0.03747936981941117 and parameters: {'learning_rate': 0.21014974142381398, 'max_depth': 5, 'n_estimators': 700, 'subsample': 0.7430795347239294, 'colsample_bytree': 0.6717899087736184, 'reg_alpha': 2.6850255387395956, 'reg_lambda': 35.1451810971428}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:23,470] Trial 18 finished with value: 0.10016330666486732 and parameters: {'learning_rate': 0.09776257594602329, 'max_depth': 4, 'n_estimators': 500, 'subsample': 0.8414533735965941, 'colsample_bytree': 0.663049357605857, 'reg_alpha': 1.1236795630009973, 'reg_lambda': 61.31865473835349}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:24,575] Trial 19 finished with value: 0.006264742613414809 and parameters: {'learning_rate': 0.1900379057461759, 'max_depth': 6, 'n_estimators': 700, 'subsample': 0.7574281904402417, 'colsample_bytree': 0.7641127428447189, 'reg_alpha': 5.8558658629940785, 'reg_lambda': 35.07010373681689}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:25,573] Trial 20 finished with value: 0.08167650178247488 and parameters: {'learning_rate': 0.0872796118921081, 'max_depth': 5, 'n_estimators': 400, 'subsample': 0.8972258519564564, 'colsample_bytree': 0.8427792910805373, 'reg_alpha': 3.160920085992906, 'reg_lambda': 64.81229611513352}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:27,436] Trial 21 finished with value: 0.17060942806832538 and parameters: {'learning_rate': 0.05896042314303948, 'max_depth': 3, 'n_estimators': 800, 'subsample': 0.7049053745911558, 'colsample_bytree': 0.7399418097022568, 'reg_alpha': 0.12730008892995937, 'reg_lambda': 45.564311092908}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:28,789] Trial 22 finished with value: 0.1278387078104434 and parameters: {'learning_rate': 0.16257715144664964, 'max_depth': 4, 'n_estimators': 800, 'subsample': 0.7043765799382441, 'colsample_bytree': 0.7523454386259976, 'reg_alpha': 0.8528740204037557, 'reg_lambda': 23.025894959572796}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:30,364] Trial 23 finished with value: 0.10053394995160814 and parameters: {'learning_rate': 0.06635450851128595, 'max_depth': 4, 'n_estimators': 800, 'subsample': 0.7976029683203203, 'colsample_bytree': 0.6861797318711532, 'reg_alpha': 1.7120412913239518, 'reg_lambda': 58.6493089523301}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:31,656] Trial 24 finished with value: -0.077067260142621 and parameters: {'learning_rate': 0.06433205223676762, 'max_depth': 7, 'n_estimators': 700, 'subsample': 0.7735452570382015, 'colsample_bytree': 0.6337249225472648, 'reg_alpha': 9.860835039597102, 'reg_lambda': 40.545453356425}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:33,121] Trial 25 finished with value: 0.17552336275673744 and parameters: {'learning_rate': 0.15865049973634188, 'max_depth': 3, 'n_estimators': 600, 'subsample': 0.7065066242575891, 'colsample_bytree': 0.7486424982597283, 'reg_alpha': 0.049031241739782766, 'reg_lambda': 28.291815015237052}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:34,049] Trial 26 finished with value: 0.13180452121688727 and parameters: {'learning_rate': 0.22476551656494484, 'max_depth': 3, 'n_estimators': 600, 'subsample': 0.7171777022480743, 'colsample_bytree': 0.7545994276844311, 'reg_alpha': 0.9779158340093179, 'reg_lambda': 9.103732931288054}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:34,443] Trial 27 finished with value: 0.009687581026591693 and parameters: {'learning_rate': 0.16279367107959902, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.6562241280472375, 'colsample_bytree': 0.8170795166566613, 'reg_alpha': 4.609418121812371, 'reg_lambda': 42.29310266968885}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:35,779] Trial 28 finished with value: 0.12275276850947037 and parameters: {'learning_rate': 0.05451564029121983, 'max_depth': 6, 'n_estimators': 500, 'subsample': 0.7158344303942548, 'colsample_bytree': 0.8584920229062014, 'reg_alpha': 1.8578538916244263, 'reg_lambda': 25.20751353490686}. Best is trial 12 with value: 0.18825719440992336.\n",
      "[I 2025-03-02 01:05:37,614] Trial 29 finished with value: 0.14657116093579944 and parameters: {'learning_rate': 0.15453892534831015, 'max_depth': 3, 'n_estimators': 800, 'subsample': 0.6695953158331533, 'colsample_bytree': 0.7860636204500716, 'reg_alpha': 0.724686222137661, 'reg_lambda': 56.09053496272382}. Best is trial 12 with value: 0.18825719440992336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.10909373319085952, 'max_depth': 3, 'n_estimators': 800, 'subsample': 0.7494334255183932, 'colsample_bytree': 0.7309266965702423, 'reg_alpha': 0.004675858754265516, 'reg_lambda': 46.766727365670086}\n",
      "Best CV R²: 0.18825719440992336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrk\\PycharmProjects\\int20h-2025-xdboobs\\pipelines\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:05:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025/03/02 01:06:08 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/03/02 01:06:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run languid-hound-649 at: https://b2fd-91-123-155-204.ngrok-free.app/#/experiments/531295962442669067/runs/b1c7997fd0bc4a8580f5eb30fffe2027\n",
      "🧪 View experiment at: https://b2fd-91-123-155-204.ngrok-free.app/#/experiments/531295962442669067\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T23:53:13.367524Z",
     "start_time": "2025-03-01T23:53:13.357506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_test_df(submission_df: pd.DataFrame, train_df: pd.DataFrame):\n",
    "    submission_df[\"merchant_id\"] = submission_df[\"merchant_id_day\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    submission_df[\"date\"] = pd.to_datetime(submission_df[\"merchant_id_day\"].apply(lambda x: x.split(\"_\")[1]))\n",
    "\n",
    "    feature_columns = get_feature_columns()\n",
    "\n",
    "    test_rows = []\n",
    "    for idx, row in submission_df.iterrows():\n",
    "        merchant_id = row[\"merchant_id\"]\n",
    "        forecast_date = row[\"date\"]\n",
    "\n",
    "        merchant_hist = train_df[train_df[\"merchant_id\"] == merchant_id]\n",
    "        if merchant_hist.empty:\n",
    "            baseline = {feat: 0 for feat in feature_columns}\n",
    "        else:\n",
    "            baseline = merchant_hist.sort_values(\"date\").iloc[-1].to_dict()\n",
    "\n",
    "        baseline[\"date_ordinal\"] = forecast_date.toordinal()\n",
    "        baseline[\"day_of_week\"] = forecast_date.dayofweek\n",
    "        baseline[\"month\"] = forecast_date.month\n",
    "\n",
    "        test_rows.append(baseline)\n",
    "\n",
    "    return pd.DataFrame(test_rows)[feature_columns]\n",
    "\n",
    "\n",
    "def create_submission(submission_df: pd.DataFrame, model_uri: str):\n",
    "    processed_df = read_dataframe_from_s3(os.getenv(\"BUCKET_NAME\"), \"data/processed_data.parquet\")\n",
    "\n",
    "    test_df = create_test_df(submission_df, processed_df)\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "    test_df[\"risk_metric_pred\"] = model.predict(test_df)\n",
    "\n",
    "    final_submission_df = pd.DataFrame({\n",
    "        \"merchant_id_day\": submission_df[\"merchant_id_day\"],\n",
    "        \"risk_metric\": test_df[\"risk_metric_pred\"]\n",
    "    })\n",
    "    return final_submission_df"
   ],
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T23:53:55.080691Z",
     "start_time": "2025-03-01T23:53:50.059642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_submission_df = create_submission(pd.read_csv(\"../data/sample_submission.csv\"),\n",
    "                  \"s3://int20h-data/mlflow_artifacts/531295962442669067/b1c7997fd0bc4a8580f5eb30fffe2027/artifacts/xgboost_model\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:01<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-01T18:20:42.564003Z",
     "iopub.execute_input": "2025-03-01T18:20:42.56496Z",
     "iopub.status.idle": "2025-03-01T18:21:30.281977Z",
     "shell.execute_reply.started": "2025-03-01T18:20:42.564915Z",
     "shell.execute_reply": "2025-03-01T18:21:30.279809Z"
    },
    "ExecuteTime": {
     "end_time": "2025-03-01T23:56:13.907320Z",
     "start_time": "2025-03-01T23:56:13.898353Z"
    }
   },
   "cell_type": "code",
   "source": "final_submission_df.to_csv(\"submission.csv\", index=False)",
   "outputs": [],
   "execution_count": 143
  },
  {
   "cell_type": "code",
   "source": "final_submission_df",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-03-01T23:56:16.759736Z",
     "start_time": "2025-03-01T23:56:16.746039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     merchant_id_day  risk_metric\n",
       "0     8508273933093481573_2024-08-12     2.883748\n",
       "1     8508273933093481573_2024-08-13     2.883748\n",
       "2     8508273933093481573_2024-08-14     2.885600\n",
       "3     8508273933093481573_2024-08-15     2.885795\n",
       "4     8508273933093481573_2024-08-16     2.887431\n",
       "..                               ...          ...\n",
       "541  11019390644840797009_2025-02-05     0.894275\n",
       "542  11019390644840797009_2025-02-06     0.894295\n",
       "543  11019390644840797009_2025-02-07     0.895400\n",
       "544  11019390644840797009_2025-02-08     0.895146\n",
       "545  11019390644840797009_2025-02-09     0.894860\n",
       "\n",
       "[546 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_id_day</th>\n",
       "      <th>risk_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8508273933093481573_2024-08-12</td>\n",
       "      <td>2.883748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8508273933093481573_2024-08-13</td>\n",
       "      <td>2.883748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8508273933093481573_2024-08-14</td>\n",
       "      <td>2.885600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8508273933093481573_2024-08-15</td>\n",
       "      <td>2.885795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8508273933093481573_2024-08-16</td>\n",
       "      <td>2.887431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>11019390644840797009_2025-02-05</td>\n",
       "      <td>0.894275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>11019390644840797009_2025-02-06</td>\n",
       "      <td>0.894295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>11019390644840797009_2025-02-07</td>\n",
       "      <td>0.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>11019390644840797009_2025-02-08</td>\n",
       "      <td>0.895146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>11019390644840797009_2025-02-09</td>\n",
       "      <td>0.894860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
